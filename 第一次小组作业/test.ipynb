{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对波士顿房价数据集进行预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 一、从excel表格中读取数据内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   #调库\n",
    "df = pd.read_excel('Poston.xlsx')  #读取数据\n",
    "boston = pd.DataFrame(df)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看表的基本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('表的维度查看:')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('表的每一列数据格式查看')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各数据间相关性的初步调查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道，最后一行MEDV（自住房屋房价中位数）是我们要注意的标签。通过相关性，我们能发现LSTAT以及RM同MEDV的相关性最大，为主要特征。于是我们着手研究这两个特征与标签间的关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 利用matplotlib对数据进行可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先研究RM与MEDV的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(boston['RM'],boston['MEDV'],alpha=0.5)\n",
    "plt.xlabel('RM')\n",
    "plt.ylabel('MEDV')\n",
    "plt.title('RM VS MEDV')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再研究RM与MEDV的关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(boston['LSTAT'],boston['MEDV'],alpha=0.5)\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')\n",
    "plt.title('LSTAT VS MEDV')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来利用线性回归绘制拟合图像\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_excel('Poston.xlsx')\n",
    "boston = pd.DataFrame(df)\n",
    "\n",
    "# 提取特征和目标变量\n",
    "X_rm = boston['RM'].values.reshape(-1, 1)\n",
    "X_lstat = boston['LSTAT'].values.reshape(-1, 1)\n",
    "y = boston['MEDV'].values.reshape(-1, 1)\n",
    "\n",
    "# 添加偏置项！！！\n",
    "X_rm = np.hstack([np.ones((X_rm.shape[0], 1)), X_rm])\n",
    "X_lstat = np.hstack([np.ones((X_lstat.shape[0], 1)), X_lstat])\n",
    "\n",
    "# 最小二乘法实现\n",
    "def least_squares(X, y):\n",
    "    theta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "    return theta\n",
    "\n",
    "# 梯度下降法实现\n",
    "def gradient_descent(X, y, learning_rate=0.01, n_iterations=1000):\n",
    "    theta = np.zeros((X.shape[1], 1))\n",
    "    m = len(y)\n",
    "    for _ in range(n_iterations):\n",
    "        gradients = 2/m * X.T @ (X @ theta - y)\n",
    "        theta -= learning_rate * gradients\n",
    "    return theta\n",
    "\n",
    "# 最小二乘法\n",
    "theta_rm_ls = least_squares(X_rm, y)\n",
    "theta_lstat_ls = least_squares(X_lstat, y)\n",
    "\n",
    "# 梯度下降法\n",
    "theta_rm_gd = gradient_descent(X_rm, y)\n",
    "theta_lstat_gd = gradient_descent(X_lstat, y)\n",
    "\n",
    "# 打印结果\n",
    "print(\"最小二乘法 - RM 和 MEDV 的theta:\", theta_rm_ls.flatten())\n",
    "print(\"最小二乘法 - LSTAT 和 MEDV 的thera:\", theta_lstat_ls.flatten())\n",
    "print(\"梯度下降法 - RM 和 MEDV 的theta:\", theta_rm_gd.flatten())\n",
    "print(\"梯度下降法 - LSTAT 和 MEDV 的theta:\", theta_lstat_gd.flatten())\n",
    "\n",
    "# 绘制结果\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# RM 和 MEDV 的关系\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_rm[:, 1], y, alpha=0.5, color='blue', label='Data')\n",
    "plt.plot(X_rm[:, 1], X_rm @ theta_rm_ls, color='red', label='Least Squares')\n",
    "plt.plot(X_rm[:, 1], X_rm @ theta_rm_gd, color='green', label='Gradient Descent')\n",
    "plt.xlabel('RM')\n",
    "plt.ylabel('MEDV')\n",
    "plt.title('RM vs MEDV')\n",
    "plt.legend()\n",
    "\n",
    "# LSTAT 和 MEDV 的关系\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_lstat[:, 1], y, alpha=0.5, color='blue', label='Data')\n",
    "plt.plot(X_lstat[:, 1], X_lstat @ theta_lstat_ls, color='red', label='Least Squares')\n",
    "plt.plot(X_lstat[:, 1], X_lstat @ theta_lstat_gd, color='green', label='Gradient Descent')\n",
    "plt.xlabel('LSTAT')\n",
    "plt.ylabel('MEDV')\n",
    "plt.title('LSTAT vs MEDV')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过上面的图象我们可以知道，最小二乘法可以完美的拟合图像，但是对特殊数据比较敏感；而梯度下降法的效率更高，但是如果迭代次数设置不当，可能会出现跑超时的情况（如右图）。通过图像，便可以对房价进行一定程度的预测。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过对数据的粗略处理，我们知道了和房价最相关的两个数据；再通过线性回归，我们便可以通过这两个数据实现对房价的预测，并提升预测准度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mat_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
